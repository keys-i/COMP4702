{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEnOaZna9Rzx"
      },
      "source": [
        "# W5 Practicals - Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aims:\n",
        "* To gain some practical experience in evaluating supervised machine learning\n",
        "models.\n",
        "* To produce some assessable work for this subject."
      ],
      "metadata": {
        "id": "agqTYvbq9hda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procedure:\n",
        "In Prac W2 we applied k-NN and decision tree models to simple classification and regression datasets. The evaluation of the models was based on a single 70/30 split of the data into training and test data. In this Prac we will look more closely at the evaluation of these models.\n",
        "> Select one of the questions (3 – 6) from Prac W2 and revisit it for this prac."
      ],
      "metadata": {
        "id": "baVAWGvq9wQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> On blackboard you will find a [link](https://docs.google.com/spreadsheets/d/1HAIDBp9ofIeEp5_braHBnwJ-heN8qdaxn5qk3q1c0vo/edit?usp=sharing) to a Google spreadsheet. Go there and enter your answers for Q2 – Q5."
      ],
      "metadata": {
        "id": "PKmP9mvo-jhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Common Imports\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "QoIDAKY__Jjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ANSI color\n",
        "class color:\n",
        "  YELLOW_BOLD = '\\033[1;33m'\n",
        "  END = '\\033[0m'"
      ],
      "metadata": {
        "id": "jUmAJwF5s8aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1: Repeat Q2 from Prac W2 10 times, saving the 10 resulting training and test sets."
      ],
      "metadata": {
        "id": "u3RTU1y_9oXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specific Imports\n",
        "import os\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "W3JVLLgw_DeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_split_data(CSV_file, test_size=0.3, random_state=42):\n",
        "  \"\"\"\n",
        "  Loads a CSV file and splits it into training and test sets.\n",
        "\n",
        "  Parameters:\n",
        "  CSV_file (str): The path to the CSV file.\n",
        "  test_size (float): The proportion of the data to include in the test split.\n",
        "  random_state (int): The seed used by the random number generator.\n",
        "\n",
        "  Returns:\n",
        "  tuple: A tuple containing the training and test sets.\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(CSV_file, header=None)\n",
        "  X, y = df.iloc[:, :-1].values, df.iloc[:, -1].values\n",
        "  return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "def save_split_data(data_splits, iteration, headers, save_dir=\"datasets\"):\n",
        "    \"\"\"\n",
        "    Saves the combined X_train, y_train, X_test, and y_test for one iteration to CSV files.\n",
        "    The files are named X{iteration}_train.csv and X{iteration}_test.csv.\n",
        "\n",
        "    Parameters:\n",
        "    data_splits (tuple): A tuple containing the training and test sets.\n",
        "    iteration (int): The iteration number.\n",
        "    headers (list): A list of column headers for the CSV files.\n",
        "    save_dir (str): The directory where the CSV files will be saved.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "      os.makedirs(save_dir)\n",
        "\n",
        "    train_dir = os.path.join(save_dir, 'train')\n",
        "    test_dir = os.path.join(save_dir, 'test')\n",
        "\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = data_splits\n",
        "\n",
        "    def save_data(X, y, filename):\n",
        "        combined_data = pd.DataFrame(X)\n",
        "        combined_data['target'] = y\n",
        "        combined_data.columns = headers\n",
        "        combined_data.to_csv(filename, index=False)\n",
        "\n",
        "    save_data(X_train, y_train, os.path.join(train_dir, f\"X{iteration}_train.csv\"))\n",
        "    save_data(X_test, y_test, os.path.join(test_dir, f\"X{iteration}_test.csv\"))\n",
        "\n",
        "    print(f\"Data saved as 'train/X{iteration}_train.csv' and 'test/X{iteration}_test.csv'\")\n",
        "\n",
        "REGR_CSV = 'w3regr.csv'\n",
        "regr_headers = [\"Feature1\", \"Feature2\"]\n",
        "print(f\"{color.YELLOW_BOLD}Classification{color.END}\")\n",
        "for i in range(1,11):\n",
        "  data_splits = load_and_split_data(REGR_CSV, test_size=0.3, random_state=None)  # random_state=None for variability\n",
        "  save_split_data(data_splits, i, regr_headers, \"dataset/classification\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "CLASSIF_CSV = 'w3classif.csv'\n",
        "classif_headers = [\"feature1\", \"feature2\", \"target\"]\n",
        "print(f\"{color.YELLOW_BOLD}Regression{color.END}\")\n",
        "for i in range(1,11):\n",
        "  data_splits = load_and_split_data(CLASSIF_CSV, test_size=0.3, random_state=None)  # random_state=None for variability\n",
        "  save_split_data(data_splits, i, classif_headers, \"datasets/regression\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmdSBOaC-dYf",
        "outputId": "64cc25d9-eb87-4943-bdbc-90885247907f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mClassification\u001b[0m\n",
            "Data saved as 'train/X1_train.csv' and 'test/X1_test.csv'\n",
            "Data saved as 'train/X2_train.csv' and 'test/X2_test.csv'\n",
            "Data saved as 'train/X3_train.csv' and 'test/X3_test.csv'\n",
            "Data saved as 'train/X4_train.csv' and 'test/X4_test.csv'\n",
            "Data saved as 'train/X5_train.csv' and 'test/X5_test.csv'\n",
            "Data saved as 'train/X6_train.csv' and 'test/X6_test.csv'\n",
            "Data saved as 'train/X7_train.csv' and 'test/X7_test.csv'\n",
            "Data saved as 'train/X8_train.csv' and 'test/X8_test.csv'\n",
            "Data saved as 'train/X9_train.csv' and 'test/X9_test.csv'\n",
            "Data saved as 'train/X10_train.csv' and 'test/X10_test.csv'\n",
            "\n",
            "\n",
            "\u001b[1;33mRegression\u001b[0m\n",
            "Data saved as 'train/X1_train.csv' and 'test/X1_test.csv'\n",
            "Data saved as 'train/X2_train.csv' and 'test/X2_test.csv'\n",
            "Data saved as 'train/X3_train.csv' and 'test/X3_test.csv'\n",
            "Data saved as 'train/X4_train.csv' and 'test/X4_test.csv'\n",
            "Data saved as 'train/X5_train.csv' and 'test/X5_test.csv'\n",
            "Data saved as 'train/X6_train.csv' and 'test/X6_test.csv'\n",
            "Data saved as 'train/X7_train.csv' and 'test/X7_test.csv'\n",
            "Data saved as 'train/X8_train.csv' and 'test/X8_test.csv'\n",
            "Data saved as 'train/X9_train.csv' and 'test/X9_test.csv'\n",
            "Data saved as 'train/X10_train.csv' and 'test/X10_test.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2: Calculate the training and test set errors over all of the datasets from Q1 and calculate the average training and test errors over the 10 trials. Are the averages lower or higher than the values you found in Prac W3 (or alternatively compare with the values for the first of your 10 runs)?\n"
      ],
      "metadata": {
        "id": "_gSj0SfW-W1f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQIDtQYD-dV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3: Repeat Q1 and Q2 but use a different split – try 50/50 or 90/10. Compare your average error values with those you found in Q2."
      ],
      "metadata": {
        "id": "L5QypmlR-Yd5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5hlse_bb-m43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4: Calculate the sample standard deviation of your training and test set error values over the 10 trials from Q2 and Q3. What do you observe?"
      ],
      "metadata": {
        "id": "j4na0AUP-Z4i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y6ZRBkeH-nX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5: Perform 10-fold cross validation using your model and the (original) dataset (use existing Matlab or python functions to do this). What are the mean and standard devations of the cross-validation error?"
      ],
      "metadata": {
        "id": "jdQZE4Yl-bSp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ich62oC4-nsy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}